# -*- coding: utf-8 -*-
"""Tugas Besar 2 ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1my_JXgu1iZwuSjE7Q3dKqn0Rtr61ZD6j

# IMPORT LIBRARY
"""

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, average_precision_score, confusion_matrix
from sklearn import preprocessing
from scipy.spatial import distance
from operator import itemgetter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import matplotlib
import time
from mpl_toolkits import mplot3d
import statistics
import missingno as msno

"""## Import dataset yang telah disediakan"""

dataset=pd.read_csv("https://raw.githubusercontent.com/reziarsyi/Arzi/main/kendaraan_train.csv")
dataset_test = pd.read_csv("https://raw.githubusercontent.com/reziarsyi/Arzi/main/kendaraan_test.csv")

dataset.head()

"""====================================================================================="""

dataset.shape

dataset.dtypes

"""### **`DATA PRE-PROCESSING`**"""

#Untuk Melihat Data NaN (kosong) disetiap kolom
msno.matrix(dataset)

dataset.isnull().sum()

"""# Mengganti isi data Missing Value(NaN) pada setiap Kolom"""

dataset["Jenis_Kelamin"] = dataset["Jenis_Kelamin"].replace(np.NaN, np.random.choice(a=["Pria","Wanita"],p=[0.54,0.46])) #Dengan Probabilitas
dataset["Umur"] = dataset["Umur"].replace(np.NaN, dataset["Umur"].mean()) #Dengan Rata-Rata
dataset["SIM"] = dataset["SIM"].replace(np.NaN, dataset["SIM"].mean())
dataset["Kode_Daerah"] = dataset["Kode_Daerah"].replace(np.NaN, statistics.mode(dataset["Kode_Daerah"])) 
dataset ["Sudah_Asuransi"] = dataset["Sudah_Asuransi"].replace(np.NaN, np.random.choice(a=[0, 1],p=[0.5417, 0.4583]))
dataset ["Umur_Kendaraan"] = dataset["Umur_Kendaraan"].replace(np.NaN, np.random.choice(a=["< 1 Tahun", "1-2 Tahun", "> 2 Tahun"],p=[0.431, 0.527, 0.042])) 
dataset ["Kendaraan_Rusak"] = dataset["Kendaraan_Rusak"].replace(np.NaN, np.random.choice(a=["Pernah", "Tidak"],p=[0.5355, 0.4645]))
dataset ["Premi"] = dataset["Premi"].replace(np.NaN, dataset["Premi"].mean()) 
dataset["Kanal_Penjualan"] = dataset["Kanal_Penjualan"].replace(np.NaN, 152) 
dataset ["Lama_Berlangganan"] = dataset[ "Lama_Berlangganan"].replace(np.NaN, dataset["Lama_Berlangganan"].mean())

print(dataset.isnull().sum()) 
dataset.shape

dataset.head()

"""#Konversi Tipe Data"""

convert_data_types={
    #'id' : int,
    'Jenis_Kelamin' : object,
    'Umur' : int,
    'SIM' : int,
    'Kode_Daerah' : int,
    'Sudah_Asuransi' : int,
    'Umur_Kendaraan' : object,
    'Kendaraan_Rusak' : object,
    'Premi' : int,
    'Kanal_Penjualan' : int,
    'Lama_Berlangganan' : int
}
dataset = dataset.astype(convert_data_types)
dataset_test = dataset_test.astype(convert_data_types)
dataset.dtypes

"""# Melakukan Scalling Data pada beberapa kolom"""

scale_Kendaraan_Rusak = {"Tidak":0,"Pernah":1}
dataset["Kendaraan_Rusak"] = dataset["Kendaraan_Rusak"].replace(scale_Kendaraan_Rusak)
dataset_test["Kendaraan_Rusak"] = dataset_test["Kendaraan_Rusak"].replace(scale_Kendaraan_Rusak)

scale_Jenis_Kelamin = {"Wanita":0,"Pria":1}
dataset["Jenis_Kelamin"] = dataset["Jenis_Kelamin"].replace(scale_Jenis_Kelamin)
dataset_test["Jenis_Kelamin"] = dataset_test["Jenis_Kelamin"].replace(scale_Jenis_Kelamin)

#DROP BEBERAPA KOLOM PADA DATA

umurKD = pd.get_dummies(dataset["Umur_Kendaraan"], drop_first=True)
dataset = pd.concat([dataset,umurKD], axis=1)
dataset.drop(["Umur_Kendaraan","id","Kode_Daerah","Kanal_Penjualan"], axis=1,inplace=True)

umurKD = pd.get_dummies(dataset_test["Umur_Kendaraan"], drop_first=True)
dataset_test = pd.concat([dataset_test,umurKD], axis=1)
dataset_test.drop(["Umur_Kendaraan","Kode_Daerah","Kanal_Penjualan"], axis=1,inplace=True)

dataset.head()

"""# =========== **PERMODELAN menggunakan KNN** =================

#Melakukan Feature Selection
"""

x1=dataset.iloc[:, [0,1,2,3,4,5,6,8,9]].values
y1=dataset.iloc[:,7].values

x2=dataset_test.iloc[:,[0,1,2,3,4,5,6,8,9]].values
y2=dataset_test.iloc[:,7].values

min_max_scaler = preprocessing.MinMaxScaler()
x1 = min_max_scaler.fit_transform(x1)
x2 = min_max_scaler.fit_transform(x2)

"""## **Melakukan Splitting Data**"""

X_train , X_test, y_train, y_test = train_test_split(x1,y1,test_size=0.3) #Melakukan Spilting data

"""## MODELLING"""

def most_common(lst):
    return max(set(lst), key=lst.count)

Accuracy=list()       
timeRequired=list()
#fungsi untuk  x (independen) variabel, y (dependent) varibale dan N (jumlah tetangga)
def simpleKNN(X,y,N): 
    start = time.process_time()
    global X_train,X_test,y_train,y_test, y_predicted 
    X_train,X_test,y_train,y_test=train_test_split(x1,y1,test_size=0.33,random_state=2) #untuk spliting data pada dataset train dan dataset test
    columns=len(X_train.columns) #Untuk MEnyimpan jumlah dimensi X
    y_predicted=list()
    for index1,TestRow in X_test.iterrows(): #iterasi pada tes yang ditetapkan untuk melakukan prediksi pada setiap baris 
        TestRowTempValue=list()
        for i in range(0,columns): 
            TestRowTempValue.append(TestRow.iloc[i]) #menyimpan data baris untuk menghitung jarak
        temp=list()
        for index2,trainRow in X_train.iterrows(): #iterasi atas pelatihan data untuk menghitung jarak dari setiap titik data
            TrainRowTempValue=list()
            for i in range(0,columns):
                TrainRowTempValue.append(trainRow.iloc[i])
            distanceFromPoint=distance.euclidean(TestRowTempValue,TrainRowTempValue) #store all distace and data points
            temp.append((index1,index2,distanceFromPoint,y_train.loc[index2][0]))
            sortedDis=sorted(temp, key=itemgetter(2)) #sort based on distance calculated
            Ytop=sortedDis[:N]  #it will store nearest points
            neighbours=list()
            for i in Ytop:
                neighbours.append(i[len(i)-1])
        y_predicted.append(most_common(neighbours))
    #print("Confusion Matrix \n",confusion_matrix(y_test,y_predicted),"\n","Accuracy Score",accuracy_score(y_test,y_predicted),"\n","Precison",average_precision_score(y_test,y_predicted))
    Accuracy.append(accuracy_score(y_test,y_predicted))
    timeRequired.append((time.process_time() - start))

from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=15)

"""## = Nilai N Terbaik ="""

neigh.fit(X_train,y_train)

PredictedSKL=neigh.predict(x1)

print("Confusion Matrix Kendaraan_Train \n",confusion_matrix(y1,PredictedSKL),"\n","Accuracy Score",accuracy_score(y1,PredictedSKL),"\n","Precison",average_precision_score(y1,PredictedSKL))

PredictedSKL2=neigh.predict(x2)

print("Confusion Matrix Kendaraan_Test \n",confusion_matrix(y2,PredictedSKL2),"\n","Accuracy Score",accuracy_score(y2,PredictedSKL2),"\n","Precison",average_precision_score(y2,PredictedSKL2))

print(dataset)

dataset.head()